{"cells":[{"cell_type":"markdown","metadata":{"id":"sU9IP4T3So9t"},"source":["# Softmax_with_Lossレイヤの実装"]},{"cell_type":"code","source":["import numpy as np\n","\n","try:\n","    from google.colab import files\n","    print('Google Colab. 上での実行です')\n","    print('「ファイルを選択」から、notebook/commonフォルダのactivations.py、loss.pyを選択し、アップロードしてください')\n","    print('===========')\n","    files.upload()\n","    !mkdir common\n","    !mv *.py ./common\n","except:\n","    print('ローカル環境での実行です')\n","\n","from common.activations import softmax\n","from common.loss import cross_entropy_error"],"metadata":{"id":"5wdbF1JYSpm1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zb9cQgWRSo92"},"source":["## Softmax_with_Lossの実装"]},{"cell_type":"markdown","metadata":{"id":"BVrWTZ1ASo93"},"source":["### [演習]\n","* 以下のSoftmax_with_Lossクラスを完成させましょう"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10PR4IYLSo94"},"outputs":[],"source":["class SoftmaxWithLoss:\n","    def __init__(self):\n","        \n","        # 初期値\n","        self.loss = None\n","        self.y = None # softmaxの出力\n","        self.t = None # 正解データ\n","\n","    def forward(self, x, t):\n","        \"\"\"\n","        順伝播\n","        \"\"\"\n","        self.t = t\n","        self.y = softmax(     )\n","        self.loss = cross_entropy_error(     ,     )\n","        \n","        return self.loss\n","\n","    def backward(self, dout=1):\n","        \"\"\"\n","        逆伝播\n","        伝播する値をバッチサイズで割ること\n","        dout=1は、他のレイヤと同じ使い方ができるように設定しているダミー変数\n","        \"\"\"\n","        batch_size = self.t.shape[0]\n","        dx =      / batch_size\n","\n","        return dx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h16z62VeSo95"},"outputs":[],"source":["# 行列入力\n","x = np.array([\n","            [1, 2, 3],\n","            [3, 2, 1]])\n","t = np.array([\n","            [0, 0, 1],\n","            [1, 0, 0]])\n","\n","# 順伝播\n","softmaxloss = SoftmaxWithLoss()\n","out = softmaxloss.forward(x, t)\n","print(\"forward=\", out)\n","print()\n","print(\"ソフトマックスの出力結果=\\n\", softmaxloss.y)\n","print()\n","\n","# 逆伝播\n","dLdx = softmaxloss.backward()\n","print(\"dLdx=\\n\", dLdx)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"2_15_softmax_with_loss_trainee.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}