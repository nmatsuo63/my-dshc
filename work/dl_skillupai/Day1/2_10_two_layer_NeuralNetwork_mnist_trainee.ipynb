{"cells":[{"cell_type":"markdown","metadata":{"id":"-uikSXExNr0z"},"source":["# 2層ニューラルネットワークでMNISTを解く"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","try:\n","    from google.colab import files\n","    print('Google Colab. 上での実行です')\n","    print('「ファイルを選択」から、notebook/commonフォルダのactivations.py、grad.py、loss.pyを選択し、アップロードしてください')\n","    print('===========')\n","    files.upload()\n","    !mkdir common\n","    !mv *.py ./common\n","except:\n","    print('ローカル環境での実行です')\n","\n","from common.activations import softmax, sigmoid\n","from common.grad import numerical_gradient\n","from common.loss import cross_entropy_error"],"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":303},"id":"cG_R1Sn1NtDc","executionInfo":{"status":"ok","timestamp":1659891091954,"user_tz":-540,"elapsed":13714,"user":{"displayName":"小宮寛季","userId":"09825774445954048534"}},"outputId":"b488ffad-03fe-48fc-ce66-03b2145a6919"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Google Colab. 上での実行です\n","「ファイルを選択」から、DAY1/2_notebook/common フォルダの中身をすべてを選択し、アップロードしてください\n","===========\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-fa7db2f1-7195-4359-a85f-6290da8d15b6\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-fa7db2f1-7195-4359-a85f-6290da8d15b6\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving activations.py to activations.py\n","Saving grad.py to grad.py\n","Saving layers.py to layers.py\n","Saving loss.py to loss.py\n","Saving network.py to network.py\n","Saving network_colab.py to network_colab.py\n"]}]},{"cell_type":"markdown","metadata":{"id":"qKUEYxMkNr04"},"source":["## 2層ニューラルネットワーククラスに正解率(Accuracy)を求める関数を追加"]},{"cell_type":"markdown","metadata":{"id":"FW3I2lelNr05"},"source":["### [演習]\n","* 2層ニューラルネットワーククラスに正解率(Accuracy)を求める関数を追加しましょう"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYRl2TBbNr06"},"outputs":[],"source":["# ヒント\n","y = np.array([\n","            [0.1, 0.9],\n","            [0.8, 0.2],\n","            [0.3, 0.7]])\n","t = np.array([\n","            [0, 1],\n","            [0, 1],\n","            [1, 0]])\n","\n","y = np.argmax(y, axis=1)\n","print(\"argmax(y)=\", y)\n","\n","t = np.argmax(t, axis=1)\n","print(\"argmax(t)=\", t)\n","\n","print(np.sum(y==t))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIzpT4WJNr06"},"outputs":[],"source":["class TwoLayerNet():\n","    def __init__(self, input_size, hidden_size, output_size):\n","        \n","        # 重みの初期化\n","        self.params = {}\n","        init_std=0.01\n","        np.random.seed(1234)\n","        self.params[\"W1\"] = init_std * np.random.randn(input_size, hidden_size)\n","        self.params[\"b1\"] = np.zeros(hidden_size)\n","        self.params[\"W2\"] = init_std * np.random.randn(hidden_size, output_size)\n","        self.params[\"b2\"] = np.zeros(output_size)\n","                \n","    def predict(self, x):\n","        \"\"\"\n","        予測関数\n","        x : 入力データ\n","        \"\"\"\n","        W1, W2 = self.params[\"W1\"], self.params[\"W2\"]\n","        b1, b2 = self.params[\"b1\"], self.params[\"b2\"]\n","        \n","        h1 = np.dot(x, W1) + b1\n","        z1 = sigmoid(h1)\n","        h2 = np.dot(z1, W2) + b2\n","        y = softmax(h2)\n","        return y\n","    \n","    def loss(self, x, t):\n","        \"\"\"\n","        損失関数\n","        x : 入力データ\n","        t : 正解データ\n","        \"\"\"\n","        y = self.predict(x)\n","        loss = cross_entropy_error(y, t)\n","        return loss\n","    \n","    def gradient(self, x, t):\n","        \"\"\"\n","        勾配計算関数\n","        \"\"\"\n","        grads={}\n","        f = self.loss\n","        grads[\"W1\"] = numerical_gradient(f, x, self.params[\"W1\"], t)\n","        grads[\"b1\"] = numerical_gradient(f, x, self.params[\"b1\"], t)\n","        grads[\"W2\"] = numerical_gradient(f, x, self.params[\"W2\"], t)\n","        grads[\"b2\"] = numerical_gradient(f, x, self.params[\"b2\"], t)\n","        return grads\n","    \n","    def accuracy(self, x, t):\n","        \"\"\"\n","        正解率を算出する関数\n","        \"\"\"\n","        y = self.predict(      )\n","        y = np.argmax(    , axis=1)\n","        t = np.argmax(    , axis=1)\n","        return np.sum(   ==  ) / "]},{"cell_type":"markdown","metadata":{"id":"hI4wnbRKNr07"},"source":["## MNISTデータの読み込み"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5izEcuwNr08"},"outputs":[],"source":["# Load the MNIST dataset\n","import tensorflow as tf\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train),(X_test, y_test) = mnist.load_data()\n","\n","from sklearn.preprocessing import LabelBinarizer\n","lb = LabelBinarizer()\n","\n","train = X_train/255\n","test = X_test/255\n","train = train.reshape(-1, 28*28)\n","test = test.reshape(-1, 28*28)\n","train_labels = lb.fit_transform(y_train)\n","test_labels = lb.fit_transform(y_test)"]},{"cell_type":"markdown","metadata":{"id":"W4gl3JZJNr08"},"source":["## ミニバッチ学習を行う"]},{"cell_type":"markdown","metadata":{"id":"aN1fTciKNr09"},"source":["### [演習]\n","* 以下のミニバッチ学習を完成させましょう。  \n","* ここでは、計算が実行できることを確認できればよいので、計算に用いるデータの数は少なくしています。  \n","* 計算の進行と共に損失が小さくなっていくことを確認したい場合は、以下の条件を変更する必要があります。ただし、変更すると計算時間が長くなるのでご注意ください。  \n","```\n","x = train[:9,:]  \n","t = train_labels[:9,:]  \n","epochs = 10  \n","batch_size = 3  \n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"declfgvZNr0-"},"outputs":[],"source":["x = train[:9,:]\n","t = train_labels[:9,:]\n","epochs = 10\n","batch_size = 3\n","lr = 0.01\n","\n","# 繰り返し回数\n","xsize = x.shape[0]\n","iter_num = np.ceil(xsize / batch_size).astype(np.int) # ceilは切り上げ関数\n","\n","# 2層NNのオブジェクト生成\n","tnet = TwoLayerNet(input_size=28*28, hidden_size=100, output_size=10)\n","\n","train_loss = []\n","test_loss = []\n","train_accuracy = []\n","test_accuracy = []\n","for epoch in range(epochs):\n","    print(\"epoch=%s\"%epoch)\n","    \n","    # シャッフル\n","    idx = np.arange(xsize)\n","    np.random.shuffle(idx)\n","\n","    for it in range(iter_num):\n","        \"\"\"\n","        ランダムなミニバッチを順番に取り出す\n","        \"\"\"\n","        mask = idx[batch_size*it : batch_size*(it+1)]\n","    \n","        # ミニバッチの生成\n","        x_train = x[mask]\n","        t_train = t[mask]\n","        \n","        # 勾配の計算\n","        grads = tnet.gradient(     ,      )\n","\n","        # パラメータの更新\n","        for key in tnet.params.keys():\n","    #         print(key)\n","            tnet.params[key] -= lr * \n","\n","    ## 学習経過の記録 ##\n","    \n","    # 訓練データにおけるloss\n","    train_loss.append(tnet.loss(    ,    ))\n","    \n","    # テストデータにおけるloss\n","    test_loss.append(tnet.loss(    ,    ))\n","    \n","    # 訓練データにて精度を確認\n","    train_accuracy.append(tnet.accuracy(    ,    ))\n","\n","    # テストデータにて精度を算出\n","    test_accuracy.append(tnet.accuracy(   ,     ))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"ROukhc0CNr0-"},"outputs":[],"source":["# lossとaccuracyの変化をグラフ化\n","df_log = pd.DataFrame({\"train_loss\":train_loss,\n","             \"test_loss\":test_loss,\n","             \"train_accuracy\":train_accuracy,\n","             \"test_accuracy\":test_accuracy})\n","df_log.plot(style=['r-', 'r--', 'b-', 'b--'])\n","plt.ylim([0,3])\n","plt.ylabel(\"Accuracy or loss\")\n","plt.xlabel(\"epochs\")\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"2_10_two_layer_NeuralNetwork_mnist_trainee.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}