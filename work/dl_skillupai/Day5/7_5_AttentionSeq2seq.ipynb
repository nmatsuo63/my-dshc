{"cells":[{"cell_type":"markdown","metadata":{"id":"AqdWhaOg4vCZ"},"source":["# アテンションを用いたseq2seqモデルを計算するためのクラスを実装する"]},{"cell_type":"code","source":["import numpy as np\n","\n","try:\n","    from google.colab import files\n","    print('Google Colab. 上での実行です')\n","    print('「ファイルを選択」から、notebook/common フォルダの中身をすべてを選択し、アップロードしてください')\n","    print('===========')\n","    files.upload()\n","    !mkdir common\n","    !mv *.py ./common\n","except:\n","    print('ローカル環境での実行です')\n","\n","\n","from common.time_layers import TimeEmbedding,TimeLSTM,TimeAffine, TimeAffine,TimeSoftmaxWithLoss\n","from common.seq2seq import Encoder, Seq2seq\n","from common.attention_layer import TimeAttention\n","from common.layers import Tanh\n"],"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":721},"id":"LZ77vk8c5W67","executionInfo":{"status":"ok","timestamp":1659952850935,"user_tz":-540,"elapsed":24933,"user":{"displayName":"小宮寛季","userId":"09825774445954048534"}},"outputId":"78b339df-b7b1-4c77-afca-5d86145ec79c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Google Colab. 上での実行です\n","「ファイルを選択」から、notebook/common フォルダの中身をすべてを選択し、アップロードしてください\n","===========\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-86d2e300-1293-4da3-b7f5-a26e65e7a50f\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-86d2e300-1293-4da3-b7f5-a26e65e7a50f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving agent.py to agent.py\n","Saving attention_biseq2seq.py to attention_biseq2seq.py\n","Saving attention_layer.py to attention_layer.py\n","Saving attention_seq2seq.py to attention_seq2seq.py\n","Saving base_model.py to base_model.py\n","Saving biseq2seq.py to biseq2seq.py\n","Saving functions.py to functions.py\n","Saving layers.py to layers.py\n","Saving meiro.py to meiro.py\n","Saving optimizer.py to optimizer.py\n","Saving planner.py to planner.py\n","Saving seq2seq.py to seq2seq.py\n","Saving show_value.py to show_value.py\n","Saving time_layers.py to time_layers.py\n","Saving trainer.py to trainer.py\n","Saving util.py to util.py\n","Saving visualize_attention.py to visualize_attention.py\n"]}]},{"cell_type":"markdown","metadata":{"id":"Uap04WnT4vCi"},"source":["### [演習]\n","* 以下のAttentionEncoder,AttentionDecoder,AttentionSeq2seqクラスを完成させましょう"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zG8iFufB4vCj","executionInfo":{"status":"ok","timestamp":1659952854253,"user_tz":-540,"elapsed":307,"user":{"displayName":"小宮寛季","userId":"09825774445954048534"}}},"outputs":[],"source":["class AttentionEncoder(Encoder):\n","    \"\"\"\n","    アテンション付きエンコーダ\n","    \"\"\"\n","    def forward(self, xs):\n","        \"\"\"\n","        順伝播\n","        xs : 入力データ\n","        \"\"\"\n","        # 単語埋め込みレイヤ\n","        xs = self.embed.forward(xs)\n","        \n","        # LSTMレイヤ\n","        hs = self.lstm.forward(xs) # 全ての中間層の情報を返す\n","        \n","        return hs\n","\n","    def backward(self, dhs):\n","        \"\"\"\n","        逆伝播\n","        dhs : 勾配\n","        \"\"\"\n","        # LSTMレイヤ\n","        dout = self.lstm.backward(dhs) #  Decoderから伝わってきた勾配を全て伝える\n","        \n","        # 単語埋め込みレイヤ\n","        dout = self.embed.backward(dout)\n","        \n","        return dout\n","\n","\n","class AttentionDecoder:\n","    \"\"\"\n","    アテンション付きデコーダ\n","    \"\"\"\n","    def __init__(self, vocab_size, wordvec_size, hidden_size):\n","        V, D, H = vocab_size, wordvec_size, hidden_size\n","        rn = np.random.randn\n","\n","        # 重みの初期値\n","        embed_W = rn(V, D) / 100 # 小さな値で初期化\n","        lstm_Wx = rn(D, 4 * H) * np.sqrt(2/(D+H)) # Xavierの初期値\n","        lstm_Wh = rn(H, 4 * H) * np.sqrt(2/(H+H)) # Xavierの初期値\n","        lstm_b = np.zeros(4 * H)\n","        affine_W_c = rn(2*H, V) * np.sqrt(2/(2*H+V)) # Xavierの初期値\n","        affine_b_c = np.zeros(V)\n","        affine_W_s = rn(V, V) * np.sqrt(2/(V+V)) # Xavierの初期値\n","        affine_b_s = np.zeros(V)\n","\n","        # レイヤの定義\n","        self.embed = TimeEmbedding(embed_W)\n","        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n","        self.attention = TimeAttention()\n","        self.affine_c = TimeAffine(affine_W_c, affine_b_c)\n","        self.tanh = Tanh()\n","        self.affine_s = TimeAffine(affine_W_s, affine_b_s)\n","        layers = [self.embed, self.lstm, self.attention, self.affine_c, self.tanh, self.affine_s]\n","\n","        # パラメータ、勾配をまとめる\n","        self.params, self.grads = [], []\n","        for layer in layers:\n","            self.params += layer.params\n","            self.grads += layer.grads\n","\n","    def forward(self, xs, enc_hs):\n","        \"\"\"\n","        順伝播\n","        xs : 入力データ(教師強制用)\n","        enc_hs : エンコーダで計算された中間状態\n","        \"\"\"\n","        # 中間状態をセット\n","        h = enc_hs[:,-1] # 最後だけ使う\n","        self.lstm.set_state(h)\n","\n","        # 単語埋め込みレイヤ\n","        out = self.embed.forward(xs)\n","        \n","        # LSTMレイヤ\n","        dec_hs = self.lstm.forward(out)\n","        \n","        # アテンションレイヤ\n","        c = self.attention.forward(enc_hs, dec_hs) # エンコーダの中間状態とLSTMの中間状態を使って、エンコーダの中間状態の加重平均cを求める\n","        \n","        # 結合\n","        out = np.concatenate((c, dec_hs), axis=2)\n","        \n","        # affine_c\n","        out = self.affine_c.forward(out)\n","        \n","        # tanh\n","        out = self.tanh.forward(out)        \n","        \n","        # affine_s\n","        out = self.affine_s.forward(out)        \n","\n","        return out\n","\n","    def backward(self, dscore):\n","        \"\"\"\n","        逆伝播\n","        \"\"\"\n","        dout = self.affine_s.backward(dscore)\n","        dout = self.tanh.backward(dout)\n","        dout = self.affine_c.backward(dout)\n","        N, T, H2 = dout.shape\n","        H = H2 // 2\n","\n","        dc, ddec_hs0 = dout[:,:,:H], dout[:,:,H:]\n","        denc_hs, ddec_hs1 = self.attention.backward(dc)\n","        ddec_hs = ddec_hs0 + ddec_hs1\n","        dout = self.lstm.backward(ddec_hs)\n","        dh = self.lstm.dh\n","        denc_hs[:, -1] += dh\n","        self.embed.backward(dout)\n","\n","        return denc_hs\n","\n","    def generate(self, enc_hs, start_id, sample_size):\n","        \"\"\"\n","        予測\n","        \"\"\"\n","        sampled = []\n","        sample_id = start_id\n","        h = enc_hs[:, -1]\n","        self.lstm.set_state(h)\n","\n","        for _ in range(sample_size):\n","            x = np.array([sample_id]).reshape((1, 1))\n","\n","            out = self.embed.forward(x)\n","            dec_hs = self.lstm.forward(out)\n","            c = self.attention.forward(enc_hs, dec_hs)\n","            \n","            # 結合\n","            out = np.concatenate((c, dec_hs), axis=2)\n","\n","            # affine_c\n","            out = self.affine_c.forward(out)\n","\n","            # tanh\n","            out = self.tanh.forward(out)        \n","\n","            # affine_s\n","            out = self.affine_s.forward(out) \n","\n","            sample_id = np.argmax(out.flatten())\n","            sampled.append(sample_id)\n","\n","        return sampled\n","\n","\n","class AttentionSeq2seq(Seq2seq):\n","    \"\"\"\n","    アテンション付きseq2seqモデル\n","    \"\"\"\n","    def __init__(self, vocab_size, wordvec_size, hidden_size):\n","        args = vocab_size, wordvec_size, hidden_size\n","        \n","        # アテンション付きエンコーダ\n","        self.encoder = AttentionEncoder(*args)\n","        # アンテション付きデコーダ\n","        self.decoder = AttentionDecoder(*args)\n","        # ソフトマックス+損失\n","        self.softmax = TimeSoftmaxWithLoss()\n","        # パラメータ、勾配をそれぞれまとめる\n","        self.params = self.encoder.params + self.decoder.params\n","        self.grads = self.encoder.grads + self.decoder.grads\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5sWWaRd4vCm","executionInfo":{"status":"ok","timestamp":1659952859930,"user_tz":-540,"elapsed":301,"user":{"displayName":"小宮寛季","userId":"09825774445954048534"}},"outputId":"1ff098c6-3a0f-4669-abef-be5e64b49eba"},"outputs":[{"output_type":"stream","name":"stdout","text":["xs= [[0 1 2 0 1]\n"," [0 2 2 0 0]\n"," [1 0 0 1 2]]\n","\n","ts= [[2 1 2 2 1]\n"," [0 1 1 2 1]\n"," [0 0 2 0 2]]\n","\n","loss= 1.0986397938545522\n","\n","dout= None\n","dout=Noneになればok\n","\n"]}],"source":["# 語彙数\n","V = 3\n","# 埋め込み後次元数\n","D = 3\n","# 中間層ノード数\n","H = 4\n","# データ数\n","N = 3\n","# 単語数\n","T = 5\n","\n","# モデル構築\n","model = AttentionSeq2seq(V, D, H)\n","\n","xs = np.random.randint(0, V, N*T).reshape(N,T)\n","ts =  np.random.randint(0, V, N*T).reshape(N,T)\n","\n","print(\"xs=\", xs)\n","print()\n","print(\"ts=\", ts)\n","print()\n","\n","# 順伝播計算\n","loss = model.forward(xs, ts)\n","print(\"loss=\", loss)\n","print()\n","\n","# 逆伝播計算\n","dout = model.backward(dout=1)\n","print(\"dout=\", dout)\n","print(\"dout=Noneになればok\")\n","print()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"7_5_AttentionSeq2seq.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}